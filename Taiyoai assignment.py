# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A8hiji4XomU3ob_t8QPJs1S8MKjSNerp
"""

#greetings to evaluation team:)

!pip install requests beautifulsoup4 pandas matplotlib seaborn plotly

import requests
from bs4 import BeautifulSoup
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

class NASAEarthDataScraper:
    def __init__(self):
        # Define the URL for the NASA Earth Data website
        self.url = 'https://www.earthdata.nasa.gov/engage/open-data-services-and-software/api'

    def fetch_data(self):
        response = requests.get(self.url)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')

            # Find the section containing information about data services and APIs
            data_services_section = soup.find('section', {'id': 'data-services'})

            # Check if the section was found
            if data_services_section:
                # Extract information from the section
                data_services = []
                for service in data_services_section.find_all('div', class_='service-item'):
                    service_name = service.find('h3').text.strip()
                    service_description = service.find('p').text.strip()

                    data_services.append({'Service Name': service_name, 'Description': service_description})

                return data_services
            else:
                print("Data services section not found on the webpage.")
                return None
        else:
            print(f"Failed to retrieve data. Status code: {response.status_code}")
            return None

    def save_to_csv(self, data):
        # Specify the CSV file path within Colab (you can change this to your preferred directory)
        csv_file = '/content/nasaearthdata_services.csv'

        df = pd.DataFrame(data)

        # Save the data to the CSV file
        df.to_csv(csv_file, index=False)

    def analyze_data(self, data):
        # Create a DataFrame for analysis
        df = pd.DataFrame(data)

        # Data Cleaning (if needed)

        # Data Exploration
        service_counts = df['Service Name'].value_counts()

        # Data Visualization
        plt.figure(figsize=(10, 6))
        sns.barplot(x=service_counts.index, y=service_counts.values)
        plt.xlabel('Service Name')
        plt.ylabel('Count')
        plt.title('Service Name Counts')
        plt.xticks(rotation=90)
        plt.show()

        # Create an interactive scatter plot
        fig = px.scatter(df, x='Service Name', y='Description', title='Interactive Scatter Plot')
        fig.update_xaxes(categoryorder='total descending')
        fig.show()

if data:
    # Analyze data
    scraper.analyze_data(data)

    # Save the fetched data to a CSV file
    scraper.save_to_csv(data)
    print("Data saved to 'nasaearthdata_services.csv'.")
else:
    print("No data was fetched. Please check the website structure and code.")

import os

# Specify the CSV file path within Colab (you can change this to your preferred directory)
csv_file_path = '/content/nasaearthdata_services.csv'

# Check if the CSV file exists in the current directory
if os.path.exists(csv_file_path):
    print("CSV file 'nasaearthdata_services.csv' exists. Data was successfully saved.")
else:
    print("CSV file 'nasaearthdata_services.csv' not found. Please check the saving process.")

